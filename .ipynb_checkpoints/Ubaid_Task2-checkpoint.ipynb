{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98a4dfa4-dfcd-466c-8f24-726bedec67e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openai\n",
    "import os\n",
    "import warnings as wn\n",
    "from datetime import datetime\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain, RetrievalQA\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "from langchain.vectorstores import Qdrant, Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from api_token import LargeLanguageModel\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Suppress warnings\n",
    "wn.filterwarnings('ignore')\n",
    "\n",
    "class Chatbot:\n",
    "    def __init__(self, model_name=\"gpt-4o-mini\", embedding_model='all-MiniLM-L6-v2'):\n",
    "        self.api = LargeLanguageModel()\n",
    "        self.api_key = self.api.get_Key()\n",
    "        os.environ['OPENAI_API_KEY'] = self.api.get_gpt_key()\n",
    "        openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "        self.llm = ChatOpenAI(model=model_name)\n",
    "        self.embedding = HuggingFaceEmbeddings(model_name=embedding_model)\n",
    "        self.conversation_history = \"Hello!\"\n",
    "        self.db = self._initialize_database()\n",
    "        self.qa_chain = self._initialize_qa_chain()\n",
    "    \n",
    "    def _initialize_database(self):\n",
    "        chunk_size = 1200\n",
    "        chunk_overlap = 200\n",
    "        splitter = RecursiveCharacterTextSplitter(\n",
    "            separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"],\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=chunk_overlap,\n",
    "            is_separator_regex=False\n",
    "        )\n",
    "        \n",
    "        docs = [Document(page_content=x) for x in splitter.split_text(self.conversation_history)]\n",
    "        split_docs = splitter.split_documents(documents=docs)\n",
    "        \n",
    "        return Chroma.from_documents(\n",
    "            documents=split_docs,\n",
    "            embedding=self.embedding,\n",
    "            collection_name='langchain',\n",
    "            persist_directory='docs/chroma/',\n",
    "        )\n",
    "    \n",
    "    def _initialize_qa_chain(self):\n",
    "        template = \"\"\"\n",
    "        You are a chatbot designed to answer user questions and remember chat history with DateTime.\n",
    "        Answer the question in just 15 words.\n",
    "\n",
    "        **Chat History**: {context}\n",
    "        \n",
    "        Question: {question}\n",
    "        Answer:\n",
    "        \"\"\"\n",
    "        qa_chain_prompt = PromptTemplate.from_template(template)\n",
    "        return RetrievalQA.from_chain_type(\n",
    "            llm=self.llm,\n",
    "            chain_type='stuff',\n",
    "            retriever=self.db.as_retriever(\n",
    "                search_type='mmr',\n",
    "                search_kwargs={'k': 4, 'fetch_k': 50}\n",
    "            ),\n",
    "            return_source_documents=False,\n",
    "            chain_type_kwargs={\n",
    "                \"prompt\": qa_chain_prompt,\n",
    "                \"verbose\": False,\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    def ask_question(self, question):\n",
    "        current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        self.conversation_history += f\"[{current_time}] {question}\\n\"\n",
    "        \n",
    "        result = self.qa_chain.invoke({'query': question})\n",
    "        return result['result']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ec9c8b5-a022-4299-b501-850169945262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Usage\n",
    "chatbot = Chatbot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e3888e7-d493-461f-b31c-dfaf07a449b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 50 is greater than number of elements in index 24, updating n_results = 24\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"That's great, Junaid! Staying hydrated is important for your health and well-being.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot.ask_question(\"I'm going for drink water!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55b1a4d9-e926-4463-b07b-c3cbf7d0d684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello![2025-02-16 18:44:59] Hi how are you?\n",
      "[2025-02-16 18:45:39] I'm going for drink water!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(chatbot.conversation_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79c9476-bba0-470e-8b49-1ae1d6b8ac03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
